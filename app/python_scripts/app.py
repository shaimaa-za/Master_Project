import faiss
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from flask import Flask, request, jsonify
import cv2
import numpy as np

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask
app = Flask(__name__)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = models.mobilenet_v2(weights="DEFAULT")
model.eval()

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

feature_dimension = 1280  # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† MobileNetV2

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
faiss_index_path = "faiss_index.bin"
image_id_file = "image_id.txt"

# ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø±Ù Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø§Ù„ØµÙØ±
if os.path.exists(image_id_file):
    with open(image_id_file, "r") as f:
        image_id_counter = int(f.read().strip())
else:
    image_id_counter = 0

# ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ FAISS Index
if os.path.exists(faiss_index_path):
    faiss_index = faiss.read_index(faiss_index_path)
    print("âœ… FAISS Index loaded from file.")
else:
    faiss_index = faiss.IndexIDMap(faiss.IndexFlatL2(feature_dimension))
    print("ğŸ“¢ New FAISS Index created.")

# Ù‚Ø§Ø¦Ù…Ø© Ù„ØªØ®Ø²ÙŠÙ† Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ØµÙˆØ±
image_ids = [{"id": i, "path": f"uploaded_{i}.jpg"} for i in range(image_id_counter)]

# Ø¯Ø§Ù„Ø© ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Min-Max
def normalize_features(features):
    min_val = np.min(features)
    max_val = np.max(features)
    return (features - min_val) / (max_val - min_val)  # ØªØ·Ø¨ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Min-Max

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
def extract_features(image_path):
    print(f"Loading image from: {image_path}")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"âŒ Cannot load image: {image_path}")

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† BGR Ø¥Ù„Ù‰ RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = transform(image).unsqueeze(0)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Tensor Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬

    with torch.no_grad():
        features = model.features(image)
        features = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙƒÙŠÙŠÙ Ø§Ù„Ù…ØªÙˆØ³Ø·
        features = features.view(-1).numpy()  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© 1D

        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Min-Max Normalization
        features = normalize_features(features)

    return features.astype('float32')

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ FAISS
@app.route('/upload', methods=['POST'])
def upload_image():
    global image_id_counter
    global faiss_index

    file = request.files['image']
    image_path = f"uploaded_{image_id_counter}.jpg"
    file.save(image_path)

    try:
        features = extract_features(image_path)
    except ValueError as e:
        return jsonify({"message": str(e)}), 400

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¥Ù„Ù‰ FAISS Ù…Ø¹ Ù…Ø¹Ø±Ù Ø§Ù„ØµÙˆØ±Ø©
    image_id = image_id_counter
    faiss_index.add_with_ids(np.array([features]), np.array([image_id], dtype=np.int64))
    image_ids.append({"id": image_id, "path": image_path})

    # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø±Ù Ø§Ù„ØµÙˆØ±Ø©
    image_id_counter += 1

    # Ø­ÙØ¸ Ù…Ø¹Ø±Ù Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø­ØªÙ‰ Ù„Ø§ ÙŠØªÙ… ÙÙ‚Ø¯Ø§Ù†Ù‡ Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
    with open(image_id_file, "w") as f:
        f.write(str(image_id_counter))

    # Ø­ÙØ¸ FAISS Index Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø¶Ø§ÙØ©
    faiss.write_index(faiss_index, faiss_index_path)

    return jsonify({
        "message": "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¥Ù„Ù‰ FAISS!",
        "image_id": image_id
    })

# Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ø¬Ø¯Ù‹Ø§ ÙÙ‚Ø·
@app.route('/search', methods=['POST'])
def search_images():
    if faiss_index.ntotal == 0:
        return jsonify({"message": "âŒ No data in FAISS! Please add some images first."}), 400

    file = request.files['image']
    query_image_path = "query_image.jpg"
    file.save(query_image_path)

    try:
        query_features = extract_features(query_image_path)
    except ValueError as e:
        return jsonify({"message": str(e)}), 400

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙˆØ± ÙÙŠ FAISS
    num_images = faiss_index.ntotal  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®Ø²Ù†Ø©
    distances, indices = faiss_index.search(np.array([query_features]), k=num_images)  # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±
    print(f"ğŸ” Total images stored in FAISS: {num_images}")

    # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„ØªØ´Ø§Ø¨Ù‡ (ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ù‚ØµÙˆÙ‰ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§)
    similarity_threshold = 2.15 

    results = []
    for i, index in enumerate(indices[0]):
        if index != -1 and distances[0][i] < similarity_threshold:
            matched_image = next((img for img in image_ids if img["id"] == index), None)
            if matched_image:
                results.append({
                    "image_id": int(index),
                    "image_path": matched_image["path"],
                    "distance": float(distances[0][i])
                })
                
    print(f"ğŸ” Total similar products found: {len(results)}")

    if not results:
        return jsonify({"message": "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ± Ù…Ø´Ø§Ø¨Ù‡Ø© ÙƒÙØ§ÙŠØ©."})

    return jsonify({
        "message": "ğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«",
        "results": results
    })

if __name__ == '__main__':
    app.run(debug=True)
